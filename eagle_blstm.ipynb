{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HyTkedK5AAwU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import warnings\n",
        "# Disabling Future Warnings0\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Model, Sequential\n",
        "from keras.models import load_model as load\n",
        "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
        "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGOYNRYaABy7",
        "outputId": "986a6411-5e44-4185-9ef0-a050a7c83fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LY-NOY9LAGka"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Hacktrick/Footprints Datasets/fake.npz'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fake \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/drive/MyDrive/Hacktrick/Footprints Datasets/fake.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m real \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/Hacktrick/Footprints Datasets/real.npz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Hacktrick/Footprints Datasets/fake.npz'"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "fake = np.load('/content/drive/MyDrive/Hacktrick/Footprints Datasets/fake.npz')\n",
        "real = np.load('/content/drive/MyDrive/Hacktrick/Footprints Datasets/real.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrnkotEKAQvL",
        "outputId": "9eb70e70-21e3-4f85-b808-ebb9a4040c20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXNtJBwHAiyd"
      },
      "outputs": [],
      "source": [
        "fake_data = fake['x']\n",
        "fake_labels = fake['y']\n",
        "real_data = real['x']\n",
        "real_labels = real['y']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmoYoV16BM1i"
      },
      "outputs": [],
      "source": [
        "Tx = 1998 # The number of time steps input to the model from the spectrogram\n",
        "n_freq = 101 # Number of frequencies input to the model at each time step of the spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIgJ8P2rBOuu",
        "outputId": "3fee356c-7bcb-4623-f617-dd329633b7d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fake len: 1998\n",
            "real len: 1998\n"
          ]
        }
      ],
      "source": [
        "# Load audio segments using pydub\n",
        "# activates, negatives, backgrounds = load_raw_audio()\n",
        "\n",
        "print(\"fake len: \" + str(len(fake_data[0])))    # Should be 10,000, since it is a 10 sec clip\n",
        "print(\"real len: \" + str(len(real_data[0])))     # Maybe around 1000, since an \"activate\" audio clip is usually around 1 sec (but varies a lot)\n",
        "# print(\"activate[1] len: \" + str(len(activates[1])))     # Different \"activate\" clips can have different lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "een7RHufBP6-"
      },
      "outputs": [],
      "source": [
        "# x = fake_data + real_data\n",
        "# y = fake_labels + real_labels\n",
        "\n",
        "x = np.concatenate((fake_data, real_data), axis=0).astype(np.float64)\n",
        "# .astypefloat\n",
        "y = np.concatenate((fake_labels, real_labels), axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52PcfDhPUz3G"
      },
      "outputs": [],
      "source": [
        "clip_min = -1e18\n",
        "clip_max = 1e18\n",
        "# clip_min = np.finfo(np.float64).max\n",
        "# clip_max = np.finfo(np.float64).min\n",
        "x = np.clip(x, clip_min, clip_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DFQ5GuhMGgP",
        "outputId": "3695fcc3-84d6-4578-ed85-2ab621aa13f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1500, 1998, 101)\n",
            "(1500, 496)\n"
          ]
        }
      ],
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmJdnjAdOFsr"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-d5LabHMRE6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
        "from tensorflow.keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL5bzYzkBR36"
      },
      "outputs": [],
      "source": [
        "# # UNQ_C5\n",
        "# # GRADED FUNCTION: modelf_bidirectional_lstm\n",
        "\n",
        "# def modelf_bidirectional_lstm(input_shape):\n",
        "#     \"\"\"\n",
        "#     Function creating the model's graph in Keras with bidirectional LSTM layers.\n",
        "\n",
        "#     Argument:\n",
        "#     input_shape -- shape of the model's input data (using Keras conventions)\n",
        "\n",
        "#     Returns:\n",
        "#     model -- Keras model instance\n",
        "#     \"\"\"\n",
        "\n",
        "#     X_input = Input(shape=input_shape)\n",
        "\n",
        "#     ### START CODE HERE ###\n",
        "\n",
        "#     # Step 1: CONV layer (≈4 lines)\n",
        "#     # Add a Conv1D with 196 units, kernel size of 15 and stride of 4\n",
        "#     X = Conv1D(filters=196, kernel_size=15, strides=4)(X_input)\n",
        "#     # Batch normalization\n",
        "#     X = BatchNormalization()(X)\n",
        "#     # ReLu activation\n",
        "#     X = Activation('relu')(X)\n",
        "#     # dropout (use 0.8)\n",
        "#     X = Dropout(rate=0.8)(X)\n",
        "\n",
        "#     # Step 2: Bidirectional LSTM Layer (≈4 lines)\n",
        "#     # Bidirectional LSTM (use 128 units)\n",
        "#     X = Bidirectional(LSTM(128, return_sequences=True))(X)\n",
        "#     # dropout (use 0.8)\n",
        "#     X = Dropout(rate=0.8)(X)\n",
        "#     # Batch normalization.\n",
        "#     X = BatchNormalization()(X)\n",
        "\n",
        "#     # Step 3: Bidirectional LSTM Layer (≈4 lines)\n",
        "#     # Bidirectional LSTM (use 128 units)\n",
        "#     X = Bidirectional(LSTM(128, return_sequences=True))(X)\n",
        "#     # dropout (use 0.8)\n",
        "#     X = Dropout(rate=0.8)(X)\n",
        "#     # Batch normalization\n",
        "#     X = BatchNormalization()(X)\n",
        "#     # dropout (use 0.8)\n",
        "#     X = Dropout(rate=0.8)(X)\n",
        "\n",
        "#     # Step 4: Time-distributed dense layer (≈1 line)\n",
        "#     # TimeDistributed  with sigmoid activation\n",
        "#     X = TimeDistributed(Dense(1, activation='sigmoid'))(X)\n",
        "\n",
        "#     ### END CODE HERE ###\n",
        "\n",
        "#     model = Model(inputs=X_input, outputs=X)\n",
        "\n",
        "#     return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty3EOojcd7t1"
      },
      "outputs": [],
      "source": [
        "# UNQ_C5\n",
        "# GRADED FUNCTION: modelf_complex_bidirectional_lstm\n",
        "\n",
        "def modelf_complex_bidirectional_lstm(input_shape):\n",
        "    \"\"\"\n",
        "    Function creating the model's graph in Keras with a more complex architecture\n",
        "    using bidirectional LSTM layers.\n",
        "\n",
        "    Argument:\n",
        "    input_shape -- shape of the model's input data (using Keras conventions)\n",
        "\n",
        "    Returns:\n",
        "    model -- Keras model instance\n",
        "    \"\"\"\n",
        "\n",
        "    X_input = Input(shape=input_shape)\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Step 1: CONV layer (≈4 lines)\n",
        "    # Add a Conv1D with 256 units, kernel size of 15 and stride of 4\n",
        "    X = Conv1D(filters=256, kernel_size=15, strides=4)(X_input)\n",
        "    # Batch normalization\n",
        "    X = BatchNormalization()(X)\n",
        "    # ReLu activation\n",
        "    X = Activation('relu')(X)\n",
        "    # dropout (use 0.8)\n",
        "    X = Dropout(rate=0.8)(X)\n",
        "\n",
        "    # Step 2: Bidirectional LSTM Layer (≈4 lines)\n",
        "    # Bidirectional LSTM (use 256 units)\n",
        "    X = Bidirectional(LSTM(256, return_sequences=True))(X)\n",
        "    # dropout (use 0.8)\n",
        "    X = Dropout(rate=0.8)(X)\n",
        "    # Batch normalization.\n",
        "    X = BatchNormalization()(X)\n",
        "\n",
        "    # Step 3: Bidirectional LSTM Layer (≈4 lines)\n",
        "    # Bidirectional LSTM (use 256 units)\n",
        "    X = Bidirectional(LSTM(256, return_sequences=True))(X)\n",
        "    # dropout (use 0.8)\n",
        "    X = Dropout(rate=0.8)(X)\n",
        "    # Batch normalization\n",
        "    X = BatchNormalization()(X)\n",
        "    # dropout (use 0.8)\n",
        "    X = Dropout(rate=0.8)(X)\n",
        "\n",
        "    # Step 4: Time-distributed dense layer (≈1 line)\n",
        "    # TimeDistributed  with sigmoid activation\n",
        "    X = TimeDistributed(Dense(1, activation='sigmoid'))(X)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    model = Model(inputs=X_input, outputs=X)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3dHqsGxM4ZE"
      },
      "outputs": [],
      "source": [
        "model = modelf_complex_bidirectional_lstm(input_shape = (Tx, n_freq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXdaltZAM4v5",
        "outputId": "0ae5a65c-66a6-4eda-fce2-466230e2d63d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1998, 101)]       0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 496, 256)          388096    \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 496, 256)          1024      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 496, 256)          0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 496, 256)          0         \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 496, 512)          1050624   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 496, 512)          0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 496, 512)          2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 496, 512)          1574912   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 496, 512)          0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 496, 512)          2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 496, 512)          0         \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 496, 1)            513       \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3019265 (11.52 MB)\n",
            "Trainable params: 3016705 (11.51 MB)\n",
            "Non-trainable params: 2560 (10.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEF5_sp_RKbV",
        "outputId": "67e519de-ba02-4098-e4ad-5b7248828018"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "opt = Adam(lr=1e-6, beta_1=0.9, beta_2=0.999)\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJvJXUpZRMW0"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, batch_size = 1, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtLLkTY_RQEN",
        "outputId": "23d2eed2-d2ff-42ae-8bc2-4fe292f52658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 2s 80ms/step - loss: 0.7333 - accuracy: 0.8862\n",
            "Dev set accuracy =  0.8861693143844604\n"
          ]
        }
      ],
      "source": [
        "loss, acc, = model.evaluate(X_test, y_test)\n",
        "print(\"Dev set accuracy = \", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFkX-3tBSN6f",
        "outputId": "ea984457-facb-426a-92da-a8bc1038f45c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 68ms/step - loss: 0.7333 - accuracy: 0.8862\n",
            "Dev set accuracy =  0.8861693143844604\n"
          ]
        }
      ],
      "source": [
        "loss, acc, = model.evaluate(X_test, y_test)\n",
        "print(\"Dev set accuracy = \", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlKj6yMxiMYt"
      },
      "outputs": [],
      "source": [
        "def detect_triggerword(x, y):\n",
        "    plt.subplot(2, 1, 1)\n",
        "\n",
        "    # x = graph_spectrogram(filename)\n",
        "    # the spectrogram outputs (freqs, Tx) and we want (Tx, freqs) to input into the model\n",
        "    # x  = x.swapaxes(0,1)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    predictions = model.predict(x)\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(predictions[0,:,0])\n",
        "    plt.ylabel('probability')\n",
        "    plt.show()\n",
        "\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(y)\n",
        "    plt.ylabel('probability')\n",
        "    plt.show()\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA7z3tYTX5lz"
      },
      "outputs": [],
      "source": [
        "for idx in range(10):\n",
        "  predictions = detect_triggerword(X_test[idx], y_test[idx])\n",
        "  print(np.sum(y_test[idx] == 1))\n",
        "  print(np.sum(predictions.flatten() == 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIfvNueTlvcQ"
      },
      "outputs": [],
      "source": [
        "print(predictions.flatten() > 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjElf32omo2_",
        "outputId": "e05fbb1f-10f6-48f7-9229-d50c8f8cfdc4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save(\"/content/drive/MyDrive/Hacktrick/models/eagle_blstm.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPna6QQNnZqP"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Hacktrick/models/eagle_blstm.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw5XGhphnZQf",
        "outputId": "522f4db7-f0ec-4948-8a1e-37582ca19f1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 10s 132ms/step - loss: 0.7333 - accuracy: 0.8862\n",
            "Dev set accuracy =  0.8861693143844604\n"
          ]
        }
      ],
      "source": [
        "loss, acc, = model.evaluate(X_test, y_test)\n",
        "print(\"Dev set accuracy = \", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am4u2eoQn0Gb"
      },
      "outputs": [],
      "source": [
        "def eagle_solve(spect):\n",
        "  spect = np.expand_dims(spect, axis=0)\n",
        "  prediction = model.predict(spect)\n",
        "  prediction = prediction > 0.5\n",
        "  prediction = np.sum(prediction == True)\n",
        "  return 1 if prediction > 10 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUa2g-GCordv",
        "outputId": "41e5fa60-b74b-411d-b0bf-003b40f23138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n",
            "1\n",
            "1\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1\n",
            "1\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(eagle_solve(X_test[0]))\n",
        "print(1 if np.sum(y_test[0] == 1) == 99 else 0)\n",
        "print(eagle_solve(X_test[1]))\n",
        "print(1 if np.sum(y_test[1] == 1) == 99 else 0)\n",
        "print(eagle_solve(X_test[2]))\n",
        "print(1 if np.sum(y_test[2] == 1) == 99 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSf_atwFqDp1",
        "outputId": "0d6855f9-1fe2-4bb8-f0d2-d3b053c8d238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "4\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "8\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "10\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "12\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "14\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "15\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "17\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "19\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "21\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "25\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "27\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "29\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "30\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "32\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "34\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "39\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "40\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "41\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "42\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "45\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "46\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "47\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "48\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "51\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "53\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "55\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "57\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "58\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "60\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "61\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "63\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "66\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "70\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "76\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "77\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "78\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "80\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "82\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "83\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "84\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "85\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "87\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "88\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "90\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "91\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "94\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "95\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "96\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "97\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "98\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "101\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "102\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "103\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "104\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "107\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "109\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "110\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "114\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "115\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "118\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "119\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "123\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "124\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "125\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "126\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "129\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "131\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "134\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "136\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "137\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "138\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "139\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "141\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "143\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "144\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "145\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "146\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "148\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "152\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "153\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "154\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "155\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "156\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "161\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "162\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "164\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "166\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "170\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "171\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "173\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "174\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "176\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "177\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "178\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "180\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "182\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "186\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "187\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "188\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "189\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "193\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "195\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "197\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "199\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "201\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "202\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "203\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "204\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "205\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "206\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "209\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "214\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "215\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "217\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "218\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "223\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "224\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "228\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "230\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "232\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "233\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "235\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "240\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "241\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "243\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "244\n",
            "1/1 [==============================] - 0s 43ms/step\n"
          ]
        }
      ],
      "source": [
        "count_miss = 0\n",
        "count_1 = 0\n",
        "count_0 = 0\n",
        "for i,x in enumerate(X_test):\n",
        "  t1 = eagle_solve(x)\n",
        "  t2 = 1 if np.sum(y_test[i] == 1) >= 20 else 0\n",
        "  if t1 != t2:\n",
        "    count_1 += 1 if t2 == 1 else 0\n",
        "    count_0 += 1 if t2 == 0 else 0\n",
        "    print(i)\n",
        "    count_miss += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9Q8hHYKrPYu"
      },
      "outputs": [],
      "source": [
        "print(count_miss)\n",
        "print(count_1)\n",
        "print(count_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bHcObjqrQpM"
      },
      "outputs": [],
      "source": [
        "print(len(y_test))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
